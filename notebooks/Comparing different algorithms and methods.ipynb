{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed22f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "import pandas as pd\n",
    "from pycona import *\n",
    "from pycona.benchmarks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3165f47f",
   "metadata": {},
   "source": [
    "### Comparing interactive CA systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc632561",
   "metadata": {},
   "source": [
    "For the introductory example, we only used GrowAcq algorithm, with its default settings. In this notebook, we will first run and compare different interactive CA algorithms, and then we will see how we can customize their configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01f0f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProblemInstance: \n",
      "\n",
      "Name nurse_rostering_nurses8_shifts3_days2_nurses_per_shift2.\n",
      "\n",
      "Parameters {'shifts_per_day': 3, 'num_days': 2, 'num_nurses': 8, 'nurses_per_shift': 2}.\n",
      "\n",
      "Variables: [[[shifts[0,0,0] shifts[0,0,1]]\n",
      "  [shifts[0,1,0] shifts[0,1,1]]\n",
      "  [shifts[0,2,0] shifts[0,2,1]]]\n",
      "\n",
      " [[shifts[1,0,0] shifts[1,0,1]]\n",
      "  [shifts[1,1,0] shifts[1,1,1]]\n",
      "  [shifts[1,2,0] shifts[1,2,1]]]].\n",
      "\n",
      "Language: [(AV4) == (AV5), (AV4) != (AV5), (AV4) < (AV5), (AV4) > (AV5), (AV4) >= (AV5), (AV4) <= (AV5)].\n"
     ]
    }
   ],
   "source": [
    "# we use the running example on nurse rostering from the introductory tutorial\n",
    "instance, oracle = construct_nurse_rostering(3, 2, 8, 2)\n",
    "print(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d089bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Customizing Interactive CA systems "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266e662",
   "metadata": {},
   "source": [
    "Each interactive CA algorithm can be configured in different ways for each of the 3 main subcomponents of interactive CA systems:\n",
    "\n",
    "- qgen: An instance of QGenBase, default is None. The query generation system to be used to generate top-level queries.\n",
    "- find_scope: An instance of FindScopeBase, default is None. The FindScope system to be used for finding the scope of violated constraints.\n",
    "- findc: An instance of FindCBase, default is None. The FindConstraint system to be used for finding the exact violated constraints in the given scopes.\n",
    "\n",
    "For each of the subcomponents several choices are implemented, based on the literature. Each subcomponent of CA is implemented in a class, with different implementations of that subcomponent subclassing it.\n",
    "\n",
    "Until now, we used the default settings in **PyConA** for interactive CA systems. We will now focus on how to customize the behaviour of a given Interactive CA system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c96d8",
   "metadata": {},
   "source": [
    "#### Using a custom CA Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7743fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running growacq with <pycona.active_algorithms.mquacq2.MQuAcq2 object at 0x000001D6D4478820> as inner algorithm\n",
      "\n",
      "Learned 0 constraints in 0 queries.\n",
      "...L..\n",
      "Learned 1 constraints in 5 queries.\n",
      "....L....L.\n",
      "Learned 3 constraints in 14 queries.\n",
      "....L.....L.....L..\n",
      "Learned 6 constraints in 30 queries.\n",
      ".......L...L....L...L\n",
      "Learned 10 constraints in 47 queries.\n",
      ".....L....L.....L....L..L\n",
      "Learned 15 constraints in 67 queries.\n",
      "........L....L..\n",
      "Learned 17 constraints in 81 queries.\n",
      ".......L....L.....L..\n",
      "Learned 20 constraints in 99 queries.\n",
      "....L....L....\n",
      "Learned 22 constraints in 111 queries.\n",
      ".......L........L...L....\n",
      "Learned 25 constraints in 133 queries.\n",
      ".......L....L..L..L...\n",
      "Learned 29 constraints in 151 queries.\n",
      ".......L.....L...L...L......L....\n",
      "Learned 34 constraints in 179 queries.\n"
     ]
    }
   ],
   "source": [
    "# Creating probabilistic environment, using the default settings for all subcomponents\n",
    "env = ProbaActiveCAEnv(qgen=PQGen(), find_scope=FindScope2(), findc=FindC())\n",
    "\n",
    "ga2 = GrowAcq(env)\n",
    "learned_instance = ga2.learn(instance, oracle=oracle, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e49b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running growacq with <pycona.active_algorithms.mquacq2.MQuAcq2 object at 0x000001D6D464FE80> as inner algorithm\n",
      "\n",
      "Learned 0 constraints in 0 queries.\n",
      ".....L..\n",
      "Learned 1 constraints in 7 queries.\n",
      "......L.......L.\n",
      "Learned 3 constraints in 21 queries.\n",
      "......L........L.........L..\n",
      "Learned 6 constraints in 46 queries.\n",
      ".........L.....L....L....L\n",
      "Learned 10 constraints in 68 queries.\n",
      "........L.......L........L......L...L\n",
      "Learned 15 constraints in 100 queries.\n",
      "...........L.........L..\n",
      "Learned 17 constraints in 122 queries.\n",
      ".........L...........L.........L..\n",
      "Learned 20 constraints in 153 queries.\n",
      "...........L.............L.....\n",
      "Learned 22 constraints in 182 queries.\n",
      "................L..........L.........L..\n",
      "Learned 25 constraints in 219 queries.\n",
      ".............L........L......L.......L...\n",
      "Learned 29 constraints in 256 queries.\n",
      "............L..........L......L.............L.....L.....\n",
      "Learned 34 constraints in 307 queries.\n"
     ]
    }
   ],
   "source": [
    "# Lets use the older 'FindScope' instead of FindScope2, and see what the effect is\n",
    "env = ProbaActiveCAEnv(qgen=PQGen(), find_scope=FindScope(), findc=FindC())\n",
    "\n",
    "ga1 = GrowAcq(env)\n",
    "learned_instance = ga1.learn(instance, oracle=oracle, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f06cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CL</th>\n",
       "      <th>tot_q</th>\n",
       "      <th>top_lvl_q</th>\n",
       "      <th>tfs_q</th>\n",
       "      <th>tfc_q</th>\n",
       "      <th>avg_q_size</th>\n",
       "      <th>avg_gen_time</th>\n",
       "      <th>avg_t</th>\n",
       "      <th>max_t</th>\n",
       "      <th>tot_t</th>\n",
       "      <th>conv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>growacq findscope2</th>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>179</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "      <td>34</td>\n",
       "      <td>4.6257</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>15.4857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growacq findscope</th>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>307</td>\n",
       "      <td>69</td>\n",
       "      <td>206</td>\n",
       "      <td>32</td>\n",
       "      <td>3.9121</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.5501</td>\n",
       "      <td>12.7876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CL  tot_q  top_lvl_q  tfs_q  tfc_q  avg_q_size  \\\n",
       "growacq findscope2 0  34    179         68     77     34      4.6257   \n",
       "growacq findscope  0  34    307         69    206     32      3.9121   \n",
       "\n",
       "                      avg_gen_time   avg_t   max_t    tot_t  conv  \n",
       "growacq findscope2 0        0.1687  0.0865  0.6577  15.4857     1  \n",
       "growacq findscope  0        0.1354  0.0417  0.5501  12.7876     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can compare the detailed statistics:\n",
    "pd.concat([ga2.env.metrics.short_statistics, \n",
    "           ga1.env.metrics.short_statistics], keys=[\"growacq findscope2\", \"growacq findscope\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b7190",
   "metadata": {},
   "source": [
    "#### Comparing different algorithms\n",
    "\n",
    "First the classic QuAcq, MQuAcq and MQuAcq2 algorithms.\n",
    "\n",
    "_(by default they do not use a probabilistic environment, though you can change that)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87bfbeba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some patience needed\n",
    "qa = QuAcq()\n",
    "learned_instance = qa.learn(instance, oracle=oracle)\n",
    "\n",
    "mqa = MQuAcq()\n",
    "learned_instance = mqa.learn(instance, oracle=oracle)\n",
    "\n",
    "mqa2 = MQuAcq2()\n",
    "learned_instance = mqa2.learn(instance, oracle=oracle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bea47c",
   "metadata": {},
   "source": [
    "Then, the more recent 'GrowAcq' meta-algorithm\n",
    "\n",
    "(includes a probabilistic environment that guides query generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574847fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga24 = GrowAcq()  # AAAI24 version, decision tree with features\n",
    "learned_instance = ga24.learn(instance, oracle=oracle)\n",
    "\n",
    "ga23 = GrowAcq(ProbaActiveCAEnv(classifier=CountsPredictor()))  # CP23 version, counting based probabilities\n",
    "learned_instance = ga23.learn(instance, oracle=oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5233f789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CL</th>\n",
       "      <th>tot_q</th>\n",
       "      <th>top_lvl_q</th>\n",
       "      <th>tfs_q</th>\n",
       "      <th>tfc_q</th>\n",
       "      <th>avg_q_size</th>\n",
       "      <th>avg_gen_time</th>\n",
       "      <th>avg_t</th>\n",
       "      <th>max_t</th>\n",
       "      <th>tot_t</th>\n",
       "      <th>conv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qa</th>\n",
       "      <td>34</td>\n",
       "      <td>244</td>\n",
       "      <td>38</td>\n",
       "      <td>173</td>\n",
       "      <td>33</td>\n",
       "      <td>6.2992</td>\n",
       "      <td>1.0003</td>\n",
       "      <td>0.1682</td>\n",
       "      <td>1.8389</td>\n",
       "      <td>41.0412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mqa</th>\n",
       "      <td>34</td>\n",
       "      <td>157</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "      <td>68</td>\n",
       "      <td>2.7389</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>1.7251</td>\n",
       "      <td>9.9337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mqa2</th>\n",
       "      <td>34</td>\n",
       "      <td>201</td>\n",
       "      <td>37</td>\n",
       "      <td>125</td>\n",
       "      <td>32</td>\n",
       "      <td>4.6468</td>\n",
       "      <td>0.7745</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>1.6736</td>\n",
       "      <td>13.7633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ga23</th>\n",
       "      <td>34</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.6667</td>\n",
       "      <td>0.1079</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>10.3072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ga24</th>\n",
       "      <td>34</td>\n",
       "      <td>83</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.3976</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.7583</td>\n",
       "      <td>12.0081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CL  tot_q  top_lvl_q  tfs_q  tfc_q  avg_q_size  avg_gen_time   avg_t  \\\n",
       "qa    34    244         38    173     33      6.2992        1.0003  0.1682   \n",
       "mqa   34    157         65     24     68      2.7389        0.8791  0.0633   \n",
       "mqa2  34    201         37    125     32      4.6468        0.7745  0.0685   \n",
       "ga23  34     90         88      0      2      5.6667        0.1079  0.1145   \n",
       "ga24  34     83         81      0      2      5.3976        0.1343  0.1447   \n",
       "\n",
       "       max_t    tot_t  conv  \n",
       "qa    1.8389  41.0412     1  \n",
       "mqa   1.7251   9.9337     1  \n",
       "mqa2  1.6736  13.7633     1  \n",
       "ga23  0.4404  10.3072     1  \n",
       "ga24  0.7583  12.0081     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can compare the detailed statistics:\n",
    "out = pd.concat([a.env.metrics.short_statistics for a in [qa,mqa,mqa2,ga23,ga24]])\n",
    "out.index = [\"qa\",\"mqa\",\"mqa2\",\"ga23\",\"ga24\"]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce06ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
